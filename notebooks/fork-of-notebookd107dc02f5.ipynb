{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-29T19:47:26.704404Z","iopub.execute_input":"2022-11-29T19:47:26.705343Z","iopub.status.idle":"2022-11-29T19:47:26.739818Z","shell.execute_reply.started":"2022-11-29T19:47:26.705225Z","shell.execute_reply":"2022-11-29T19:47:26.738825Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/supervised-chess/buffer_df.feather\n","output_type":"stream"}]},{"cell_type":"code","source":"from pathlib import Path\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nimport matplotlib.pyplot as plt\n\nSQUARES = [file+str(rank+1) for file in \"abcdefgh\" for rank in range(8)]\nPROMOTION_MOVES_STRAIGHT = [file+\"7\"+file+\"8\" for file in \"abcdefgh\"]+[file+\"2\"+file+\"1\" for file in \"abcdefgh\"]\nPROMOTION_MOVES_DIAG = [\"a7b8\", \"b7a8\", \"b7c8\",\"c7b8\", \"c7d8\", \"d7c8\", \"d7e8\", \"e7d8\", \"e7f8\", \"f7e8\", \"f7g8\", \"g7f8\", \"g7h8\", \"h7g8\"] + [\"a2b1\", \"b2a1\", \"b2c1\",\"c2b1\", \"c2d1\", \"d2c1\", \"d2e1\", \"e2d1\", \"e2f1\", \"f2g1\", \"f2e1\", \"g2f1\", \"g2h1\", \"h2g1\"]\nPROMOTION_MOVES = PROMOTION_MOVES_DIAG +PROMOTION_MOVES_STRAIGHT\nMOVES = [i+f for i in SQUARES for f in SQUARES if i!=f]+[move+promotion for move in PROMOTION_MOVES  for promotion in \"nbrq\"]\nLEN_MOVES = len(MOVES)\n\ndef process_buffer_to_torch_state_64(buffer: pd.DataFrame):\n    # ouch\n    buffer[\"state_64\"] = buffer.state.apply(lambda x: x[:-3])\n    print(len(buffer.state_64.iloc[0]))\n    x = torch.tensor(np.stack(buffer.state_64.values, axis=0), dtype=torch.float32).view(-1,64)\n    y_values = torch.tensor(buffer.value.values,dtype=torch.float32).view(-1,1) # [:,1]\n    y_policy = torch.tensor(np.stack(buffer.policy.values, axis=0), dtype=torch.float32)\n    return x.cuda(), y_values.cuda(), y_policy.cuda()\n\nclass BufferDataset(Dataset):\n    def __init__(self, x, y_value, y_policy):\n        super(BufferDataset, self).__init__()\n        assert x.shape[0] == y_value.shape[0] == y_policy.shape[0]\n        self.x = x\n        self.y_value = y_value\n        self.y_policy = y_policy\n    def __len__(self):\n        return self.x.shape[0]\n\n    def __getitem__(self, index):\n        return self.x[index], self.y_value[index], self.y_policy[index]","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:47:29.698538Z","iopub.execute_input":"2022-11-29T19:47:29.699030Z","iopub.status.idle":"2022-11-29T19:47:31.638459Z","shell.execute_reply.started":"2022-11-29T19:47:29.698986Z","shell.execute_reply":"2022-11-29T19:47:31.637389Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nclass ConvBlock(nn.Module):\n    def __init__(self):\n        super(ConvBlock, self).__init__()\n        self.conv1 = nn.Conv2d(1, 256, 3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(256)\n\n    def forward(self, s):\n        s = s.view(-1, 1, 8, 8)  # batch_size x channels x board_x x board_y\n        s = F.relu(self.bn1(self.conv1(s)))\n        return s\n\nclass ResBlock(nn.Module):\n    def __init__(self, inplanes=256, planes=256, stride=1, downsample=None):\n        super(ResBlock, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = F.relu(self.bn1(out))\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += residual\n        out = F.relu(out)\n        return out\n    \nclass OutBlock(nn.Module):\n    def __init__(self):\n        super(OutBlock, self).__init__()\n        self.conv = nn.Conv2d(256, 1, kernel_size=1) # value head\n        self.bn = nn.BatchNorm2d(1)\n        self.fc1 = nn.Linear(8*8, 64)\n        self.fc2 = nn.Linear(64, 1)\n        \n        self.conv1 = nn.Conv2d(256, 128, kernel_size=1) # policy head\n        self.bn1 = nn.BatchNorm2d(128)\n        self.fc = nn.Linear(8*8*128, 4208)\n    \n    def forward(self,s):\n        v = F.relu(self.bn(self.conv(s))) # value head\n        v = v.view(-1, 8*8)  # batch_size X channel X height X width\n        v = F.relu(self.fc1(v))\n        v = F.tanh(self.fc2(v))\n        \n        p = F.relu(self.bn1(self.conv1(s))) # policy head\n        p = p.view(-1, 8*8*128)\n        p = self.fc(p)\n        p = F.log_softmax(p, dim=1)\n        return v, p\n    \nclass ChessNet(nn.Module):\n    def __init__(self):\n        super(ChessNet, self).__init__()\n        self.conv = ConvBlock()\n        for i in range(10):\n            setattr(self, f\"res_{i}\",ResBlock())\n        self.outblock = OutBlock()\n    \n    def forward(self,s):\n        s = self.conv(s)\n        for i in range(10):\n            s = getattr(self, f\"res_{i}\")(s)\n        s = self.outblock(s)\n        return s","metadata":{"execution":{"iopub.status.busy":"2022-11-29T20:34:27.182775Z","iopub.execute_input":"2022-11-29T20:34:27.183183Z","iopub.status.idle":"2022-11-29T20:34:27.202296Z","shell.execute_reply.started":"2022-11-29T20:34:27.183148Z","shell.execute_reply":"2022-11-29T20:34:27.200939Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"batch_size = 50\nepochs = 20","metadata":{"execution":{"iopub.status.busy":"2022-11-29T20:40:19.365100Z","iopub.execute_input":"2022-11-29T20:40:19.365467Z","iopub.status.idle":"2022-11-29T20:40:19.370703Z","shell.execute_reply.started":"2022-11-29T20:40:19.365437Z","shell.execute_reply":"2022-11-29T20:40:19.369537Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"\nbuffer = pd.read_feather(\"/kaggle/input/supervised-chess/buffer_df.feather\")","metadata":{"execution":{"iopub.status.busy":"2022-11-29T20:39:36.236699Z","iopub.execute_input":"2022-11-29T20:39:36.237095Z","iopub.status.idle":"2022-11-29T20:39:41.432789Z","shell.execute_reply.started":"2022-11-29T20:39:36.237062Z","shell.execute_reply":"2022-11-29T20:39:41.430981Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model = ChessNet().cuda()\nmodel.load_state_dict(torch.load(\"/kaggle/working/nn_supervised_conv_kaggle.pth\"))\nmodel.eval()\nx, y_value, y_policy = process_buffer_to_torch_state_64(buffer)\nprint(\"processed to torch\")\ndataset = BufferDataset(x=x,y_value=y_value, y_policy=y_policy)\ntrain_dataloader = DataLoader(dataset=dataset, shuffle=True, batch_size=batch_size)\n\nloss_v_f = torch.nn.MSELoss()\nloss_policy_f = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0)\nmodel.train()\n\nloss_list = []\n\nfor it in range(epochs):\n    total_loss = 0\n    for x, y_value, y_policy in train_dataloader:\n        optimizer.zero_grad()\n        y_value_pred, y_policy_pred = model(x)        \n        loss_value = loss_v_f(y_value_pred, y_value)\n        loss_policy = loss_policy_f(y_policy_pred, y_policy)\n        loss = 40*loss_value+loss_policy\n        #loss = loss_policy\n        loss.backward()\n        optimizer.step()\n        total_loss+=loss.item()\n\n    #loss_list.append(loss.cpu().mean().detach().numpy())\n    loss_list.append(total_loss)\n    #print(f\"Epoch: {it}/{epochs}, loss: {loss.mean()}\")\n    print(f\"Epoch: {it}/{epochs}, loss per epoch: {total_loss}\")\n    \n    if it%50==0:\n        torch.save(model.state_dict(), \"/kaggle/working/nn_supervised_conv_kaggle.pth\")\n        print(\"saving\")\ntorch.save(model.state_dict(), \"/kaggle/working/nn_supervised_conv_kaggle.pth\")\nplt.plot(loss_list)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T21:17:17.285494Z","iopub.execute_input":"2022-11-29T21:17:17.285910Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"64\nprocessed to torch\nEpoch: 0/20, loss per epoch: 8197.501984357834\nsaving\nEpoch: 1/20, loss per epoch: 7754.920849323273\nEpoch: 2/20, loss per epoch: 7455.1208152771\nEpoch: 3/20, loss per epoch: 7148.545227766037\nEpoch: 4/20, loss per epoch: 6899.642054319382\nEpoch: 5/20, loss per epoch: 6669.008895397186\nEpoch: 6/20, loss per epoch: 6458.516385555267\n","output_type":"stream"}]}]}