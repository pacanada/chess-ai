{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-12T18:51:34.310561Z","iopub.execute_input":"2022-12-12T18:51:34.311329Z","iopub.status.idle":"2022-12-12T18:51:34.325677Z","shell.execute_reply.started":"2022-12-12T18:51:34.311238Z","shell.execute_reply":"2022-12-12T18:51:34.324505Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/supervised-chess/buffer_df.feather\n/kaggle/input/ptversion/y_policy.pt\n/kaggle/input/ptversion/y.pt\n/kaggle/input/ptversion/x.pt\n","output_type":"stream"}]},{"cell_type":"code","source":"from pathlib import Path\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nimport matplotlib.pyplot as plt\n\nSQUARES = [file+str(rank+1) for file in \"abcdefgh\" for rank in range(8)]\nPROMOTION_MOVES_STRAIGHT = [file+\"7\"+file+\"8\" for file in \"abcdefgh\"]+[file+\"2\"+file+\"1\" for file in \"abcdefgh\"]\nPROMOTION_MOVES_DIAG = [\"a7b8\", \"b7a8\", \"b7c8\",\"c7b8\", \"c7d8\", \"d7c8\", \"d7e8\", \"e7d8\", \"e7f8\", \"f7e8\", \"f7g8\", \"g7f8\", \"g7h8\", \"h7g8\"] + [\"a2b1\", \"b2a1\", \"b2c1\",\"c2b1\", \"c2d1\", \"d2c1\", \"d2e1\", \"e2d1\", \"e2f1\", \"f2g1\", \"f2e1\", \"g2f1\", \"g2h1\", \"h2g1\"]\nPROMOTION_MOVES = PROMOTION_MOVES_DIAG +PROMOTION_MOVES_STRAIGHT\nMOVES = [i+f for i in SQUARES for f in SQUARES if i!=f]+[move+promotion for move in PROMOTION_MOVES  for promotion in \"nbrq\"]\nLEN_MOVES = len(MOVES)\n\nclass BufferDataset(Dataset):\n    def __init__(self, x, y_value, y_policy):\n        super(BufferDataset, self).__init__()\n        assert x.shape[0] == y_value.shape[0] == y_policy.shape[0]\n        self.x = x\n        self.y_value = y_value\n        self.y_policy = y_policy\n    def __len__(self):\n        return self.x.shape[0]\n\n    def __getitem__(self, index):\n        return self.x[index], self.y_value[index], self.y_policy[index]\n\ndef process_buffer_to_torch_state_64(buffer: pd.DataFrame):\n    # ouch\n    buffer[\"state_64\"] = buffer.state.apply(lambda x: x[:-3])\n    print(len(buffer.state_64.iloc[0]))\n    x = torch.tensor(np.stack(buffer.state_64.values, axis=0), dtype=torch.float32).view(-1,64)\n    y_values = torch.tensor(buffer.value.values,dtype=torch.float32).view(-1,1) # [:,1]\n    y_policy = torch.tensor(np.stack(buffer.policy.values, axis=0), dtype=torch.float32)\n    return x.cuda(), y_values.cuda(), y_policy.cuda()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-12T18:51:34.331781Z","iopub.execute_input":"2022-12-12T18:51:34.332160Z","iopub.status.idle":"2022-12-12T18:51:34.878779Z","shell.execute_reply.started":"2022-12-12T18:51:34.332124Z","shell.execute_reply":"2022-12-12T18:51:34.877794Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nclass ConvBlock(nn.Module):\n    def __init__(self):\n        super(ConvBlock, self).__init__()\n        self.conv1 = nn.Conv2d(1, 256, 3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(256)\n\n    def forward(self, s):\n        s = s.view(-1, 1, 8, 8)  # batch_size x channels x board_x x board_y\n        s = F.relu(self.bn1(self.conv1(s)))\n        return s\n\nclass ResBlock(nn.Module):\n    def __init__(self, inplanes=256, planes=256, stride=1, downsample=None):\n        super(ResBlock, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = F.relu(self.bn1(out))\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += residual\n        out = F.relu(out)\n        return out\n    \nclass OutBlock(nn.Module):\n    def __init__(self):\n        super(OutBlock, self).__init__()\n        self.conv = nn.Conv2d(256, 1, kernel_size=1) # value head\n        self.bn = nn.BatchNorm2d(1)\n        self.fc1 = nn.Linear(8*8, 64)\n        self.fc2 = nn.Linear(64, 1)\n        \n        self.conv1 = nn.Conv2d(256, 128, kernel_size=1) # policy head\n        self.bn1 = nn.BatchNorm2d(128)\n        self.fc = nn.Linear(8*8*128, 4208)\n    \n    def forward(self,s):\n        v = F.relu(self.bn(self.conv(s))) # value head\n        v = v.view(-1, 8*8)  # batch_size X channel X height X width\n        v = F.relu(self.fc1(v))\n        v = F.tanh(self.fc2(v))\n        \n        p = F.relu(self.bn1(self.conv1(s))) # policy head\n        p = p.view(-1, 8*8*128)\n        p = self.fc(p)\n        p = F.log_softmax(p, dim=1)\n        return v, p\n    \nclass ChessNet(nn.Module):\n    def __init__(self):\n        super(ChessNet, self).__init__()\n        self.conv = ConvBlock()\n        for i in range(10):\n            setattr(self, f\"res_{i}\",ResBlock())\n        self.outblock = OutBlock()\n    \n    def forward(self,s):\n        s = self.conv(s)\n        for i in range(10):\n            s = getattr(self, f\"res_{i}\")(s)\n        s = self.outblock(s)\n        return s","metadata":{"execution":{"iopub.status.busy":"2022-12-12T18:51:34.880598Z","iopub.execute_input":"2022-12-12T18:51:34.881230Z","iopub.status.idle":"2022-12-12T18:51:34.900545Z","shell.execute_reply.started":"2022-12-12T18:51:34.881191Z","shell.execute_reply":"2022-12-12T18:51:34.899549Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"batch_size = 2000\nepochs = 200","metadata":{"execution":{"iopub.status.busy":"2022-12-12T18:51:34.904064Z","iopub.execute_input":"2022-12-12T18:51:34.904475Z","iopub.status.idle":"2022-12-12T18:51:34.913218Z","shell.execute_reply.started":"2022-12-12T18:51:34.904430Z","shell.execute_reply":"2022-12-12T18:51:34.912227Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"x = torch.load(\"/kaggle/input/ptversion/x.pt\").cuda()\ny_value = torch.load(\"/kaggle/input/ptversion/y.pt\").cuda()\ny_policy = torch.load(\"/kaggle/input/ptversion/y_policy.pt\").cuda().to_dense()\nn = 1000\nx_test, x_train = x[-n:-1,:], x[0:-n,:] \ny_value_test, y_value_train = y_value[-n:-1], y_value[0:-n] \ny_policy_test, y_policy_train = y_policy[-n:-1,:], y_policy[0:-n,:] \n#buffer = pd.read_feather(\"/kaggle/input/supervised-chess/buffer_df.feather\")","metadata":{"execution":{"iopub.status.busy":"2022-12-12T18:51:34.915616Z","iopub.execute_input":"2022-12-12T18:51:34.916511Z","iopub.status.idle":"2022-12-12T18:51:36.603006Z","shell.execute_reply.started":"2022-12-12T18:51:34.916476Z","shell.execute_reply":"2022-12-12T18:51:36.600713Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"x_train.size()","metadata":{"execution":{"iopub.status.busy":"2022-12-12T18:51:36.605833Z","iopub.execute_input":"2022-12-12T18:51:36.607122Z","iopub.status.idle":"2022-12-12T18:51:36.621094Z","shell.execute_reply.started":"2022-12-12T18:51:36.607006Z","shell.execute_reply":"2022-12-12T18:51:36.619666Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"torch.Size([197229, 64])"},"metadata":{}}]},{"cell_type":"code","source":"def evaluation(model,x_test, y_test, y_policy_test):\n    y_value_pred, y_policy_pred = model(x)\n    loss_value = loss_v_f(y_value_pred, y_value)\n    loss_policy = loss_policy_f(y_policy_pred, y_policy)\n    loss = 40*loss_value+loss_policy\n    return loss_value, loss_policy, loss\n","metadata":{"execution":{"iopub.status.busy":"2022-12-12T18:51:36.624029Z","iopub.execute_input":"2022-12-12T18:51:36.625064Z","iopub.status.idle":"2022-12-12T18:51:36.632138Z","shell.execute_reply.started":"2022-12-12T18:51:36.625018Z","shell.execute_reply":"2022-12-12T18:51:36.630567Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\nmodel = ChessNet().cuda()\nmodel.load_state_dict(torch.load(\"/kaggle/working/nn_supervised_conv_kaggle.pth\"))\nmodel.eval()\n#x, y_value, y_policy = process_buffer_to_torch_state_64(buffer)\nprint(\"processed to torch\")\ndataset = BufferDataset(x=x_train, y_value=y_value_train, y_policy=y_policy_train)\ntrain_dataloader = DataLoader(dataset=dataset, shuffle=True, batch_size=batch_size)\n\nloss_v_f = torch.nn.MSELoss()\nloss_policy_f = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0)\nmodel.train()\n\nloss_list = []\nloss_test_list = []\n\nfor it in range(epochs):\n    total_loss = 0\n    for x, y_value, y_policy in train_dataloader:\n        optimizer.zero_grad()\n        y_value_pred, y_policy_pred = model(x)        \n        loss_value = loss_v_f(y_value_pred, y_value)\n        loss_policy = loss_policy_f(y_policy_pred, y_policy)\n        loss = 40*loss_value+loss_policy\n        #loss = loss_policy\n        #print(x.size())\n        loss.backward()\n        optimizer.step()\n        total_loss+=loss.item()\n        #print(\"now\")\n\n    #loss_list.append(loss.cpu().mean().detach().numpy())\n    loss_list.append(total_loss)\n    #print(f\"Epoch: {it}/{epochs}, loss: {loss.mean()}\")\n    print(f\"Epoch: {it}/{epochs}, loss per epoch: {total_loss}\")\n    if it % 1 == 0:\n        model.eval()\n        loss_value_test, loss_policy_test, loss_test = evaluation(model, x_test, y_value_test, y_policy_test)\n        model.train()\n        loss_test_list.append([it, loss_value_test.item(), loss_policy_test.item(), loss_test.item()])\n        print(\"Loss in test (loss_value_test, loss_policy_test, loss_test)\", loss_test_list[-1])\n    if it%10==0:\n        torch.save(model.state_dict(), \"/kaggle/working/nn_supervised_conv_kaggle.pth\")\n        print(\"saving\")\ntorch.save(model.state_dict(), \"/kaggle/working/nn_supervised_conv_kaggle.pth\")\nplt.plot(loss_list)\nplt.plot(pd.DataFrame(loss_test))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-12T18:52:39.306895Z","iopub.execute_input":"2022-12-12T18:52:39.307297Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"processed to torch\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/nn_supervised_conv_kaggle.pth\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}